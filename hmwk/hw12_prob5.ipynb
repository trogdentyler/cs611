{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qWpRqBMLgRoh"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trogdentyler/cs611/blob/main/hmwk/hw12_prob5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nECHhf2qjL3l",
        "outputId": "9b9da413-3f27-42c3-a3ae-50912250fcb0"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch\n",
        "!pip3 install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X38Xt6VseJys"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_7ZMZCO6jhll"
      },
      "outputs": [],
      "source": [
        "# create mnist dataset object\n",
        "\n",
        "class MNISTProcessedDataset(Dataset):\n",
        "  def __init__(self, root, train=True):\n",
        "    # download mnist data from torchvision\n",
        "    \n",
        "    self.data = datasets.MNIST(root, train=train, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    x, y = self.data[i]\n",
        "\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bCwHmHSxk6Ci"
      },
      "outputs": [],
      "source": [
        "# create CNN architecture\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomCNN, self).__init__()\n",
        "    \n",
        "    # number of classes we're fitting to\n",
        "    out_dim = 10\n",
        "\n",
        "    ############################\n",
        "    # Assign the number of input\n",
        "    # and output channels along\n",
        "    # with the kernel and padding\n",
        "    # sizes for each convolutional\n",
        "    # layer.\n",
        "    #\n",
        "    # Also assign the in feature size\n",
        "    # for your final fully connected\n",
        "    # layer.\n",
        "    #\n",
        "    # Note: your next choices are\n",
        "    # dependent upon your previous\n",
        "    # ones.\n",
        "\n",
        "    out1 = #\n",
        "    k_size1 = #\n",
        "    padd1 = #\n",
        "    max_pool_size1 = #\n",
        "\n",
        "    in2 = #\n",
        "    out2 = #\n",
        "    k_size2 = #\n",
        "    padd2 = #\n",
        "    max_pool_size2 = #\n",
        "\n",
        "    in3 = #\n",
        "    out3 = #\n",
        "    k_size3 = #\n",
        "    padd3 = #\n",
        "    max_pool_size3 = #\n",
        "\n",
        "    in_feat = #\n",
        "\n",
        "    ############################\n",
        "\n",
        "    self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(in_channels=1, out_channels=out1, kernel_size=k_size1, padding=padd1),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=max_pool_size1),    \n",
        "        )\n",
        "    \n",
        "    self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(in_channels=in2, out_channels=out2, kernel_size=k_size2, padding=padd2),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=max_pool_size2),                \n",
        "        )\n",
        "    \n",
        "    self.conv3 = nn.Sequential(         \n",
        "            nn.Conv2d(in_channels=in3, out_channels=out3, kernel_size=k_size3, padding=padd3),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=max_pool_size3),                \n",
        "        )\n",
        "    \n",
        "    # fully connected layer, output 10 classes\n",
        "    self.out = nn.Linear(in_features=in_feat, out_features=out_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "\n",
        "    # flatten the output of conv3\n",
        "    x = x.view(x.size(0), -1)       \n",
        "    output = self.out(x)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfuFsjK7ocZH",
        "outputId": "0798d7c4-405e-4d7a-cee0-333bf2484f75"
      },
      "outputs": [],
      "source": [
        "# define train and val datasets\n",
        "train_data = MNISTProcessedDataset('/tmp/mnist')\n",
        "val_data = MNISTProcessedDataset('/tmp/mnist', train=False)\n",
        "\n",
        "# define dataloaders which will shuffle our data and hand us a batch when prompted\n",
        "batch_size = 42\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "# instantiate model\n",
        "model = CustomCNN()\n",
        "model.cuda() # use the GPU for calculation with the model\n",
        "\n",
        "# instantiate optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# instantiate loss\n",
        "objective = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "7B484ktPqCqi",
        "outputId": "1812e9f2-9b0c-462f-a115-ab1f4c5998d3"
      },
      "outputs": [],
      "source": [
        "# Run your training/validation loops\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "# play with number of epochs if training loss is too high\n",
        "num_epochs = 5\n",
        "\n",
        "# loop status bar\n",
        "loop = tqdm(total=len(train_loader) * num_epochs, position=0)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # train\n",
        "  batch = 0\n",
        "\n",
        "  for x, y_truth in train_loader:\n",
        "    # send tensors to GPU\n",
        "    x, y_truth = x.cuda(non_blocking=True), y_truth.cuda(non_blocking=True)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # evaluate model on input and get loss\n",
        "    y_hat = model(x)\n",
        "    loss = objective(y_hat, y_truth)\n",
        "\n",
        "    # here we'll run through our validation/test data\n",
        "    if batch % 25 == 0:\n",
        "      train_losses.append(loss.item())\n",
        "      validation_loss_list = []\n",
        "\n",
        "      for val_x, val_y_truth in val_loader:\n",
        "        val_x, val_y_truth = val_x.cuda(non_blocking=True), val_y_truth.cuda(non_blocking=True)\n",
        "\n",
        "        val_y_hat = model(val_x)\n",
        "        validation_loss_list.append(objective(val_y_hat, val_y_truth))\n",
        "\n",
        "      validation_losses.append( (sum(validation_loss_list) / len(validation_loss_list) ).item() )\n",
        "\n",
        "    loop.set_description('epoch:{} batch:{} loss:{:.4f} val_loss:{:.4f}'.format(epoch, batch, loss.item(), validation_losses[-1]))\n",
        "    loop.update()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch += 1\n",
        "\n",
        "loop.close()\n",
        "\n",
        "# create a plot of your loss over time\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "ax.plot(range(len(validation_losses)), validation_losses, label=\"Validation loss\")\n",
        "ax.plot(range(len(train_losses)), train_losses, label=\"Training loss\")\n",
        "\n",
        "plt.xlabel(\"Time (Iterations)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RybhpGKR3mlv",
        "outputId": "71d5c186-5ef8-4743-d1cb-02cc912c806e"
      },
      "outputs": [],
      "source": [
        "# test prediction against actual labels\n",
        "imgs, lbls = next(iter(val_loader))\n",
        "imgs = imgs.cuda()\n",
        "\n",
        "test_output = model(imgs)\n",
        "pred_lbls = torch.max(test_output, 1)[1].data.cpu().numpy().squeeze()\n",
        "\n",
        "actual_lbls = lbls.numpy()\n",
        "\n",
        "print(f'Prediction number: {pred_lbls}')\n",
        "print(f'Actual number: {actual_lbls}')\n",
        "print('\\n', pred_lbls == actual_lbls)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "deeplearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
